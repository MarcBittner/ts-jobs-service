ts-jobs-service/

    .
    ├── LICENSE
    ├── README.md
    ├── build.sh
    ├── build.sh.log
    ├── config
    │   └── config.json
    ├── dist
    │   ├── config.js
    │   ├── controllers
    │   │   ├── SearchResultController.js
    │   │   └── searchController.js
    │   ├── db.js
    │   ├── index.js
    │   ├── models
    │   │   ├── SearchDefinition.js
    │   │   └── SearchResult.js
    │   ├── routes
    │   │   └── searchRoutes.js
    │   ├── services
    │   │   ├── LinkedInScraper.js
    │   │   ├── LinkedInService.js
    │   │   └── SearchManager.js
    │   ├── testDatabaseConnections.js
    │   ├── types.js
    │   └── utils
    │       └── logger.js
    ├── env
    ├── lib
    │   ├── build.bashlog
    │   ├── build.functions
    │   ├── build.log.sh
    │   ├── build.test.sh
    │   └── build.variables
    ├── logs
    │   └── app.log
    ├── migrations
    │   ├── 20240804075700-create-search-definitions.js
    │   └── 20240804075712-create-search-results.js
    ├── models
    │   └── index.js
    ├── package-lock.json
    ├── package.json
    ├── scrapedPage.bak.html
    ├── scrapedPage.html
    ├── src
    │   ├── config
    │   ├── config.ts
    │   ├── controllers
    │   │   ├── SearchController.ts
    │   │   └── SearchResultController.ts
    │   ├── db.ts
    │   ├── index.ts
    │   ├── models
    │   │   ├── SearchDefinition.ts
    │   │   └── SearchResult.ts
    │   ├── routes
    │   │   └── SearchRoutes.ts
    │   ├── services
    │   │   ├── LinkedInScraper.ts
    │   │   ├── LinkedInService.ts
    │   │   └── SearchManager.ts
    │   ├── testDatabaseConnections.ts
    │   ├── types.ts
    │   └── utils
    │       └── logger.ts
    └── tsconfig.json
    
    19 directories, 48 files

// ./src/utils/logger.ts

import winston from 'winston';

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [
    new winston.transports.Console(),
    new winston.transports.File({ filename: process.env.LOG_FILE_PATH || 'app.log' }),
  ],
});

export default logger;

// ./src/models/SearchResult.ts
import { Model, DataTypes } from 'sequelize';
import sequelize from '../db'; // Import your Sequelize instance

class SearchResult extends Model {
  public id!: number;
  public searchId!: number;
  public position!: string;
  public company!: string;
  public location!: string;
  public date!: string;
  public salary!: string;
  public jobUrl!: string;
}

SearchResult.init(
  {
    id: {
      type: DataTypes.INTEGER,
      primaryKey: true,
      autoIncrement: true,
    },
    searchId: {
      type: DataTypes.INTEGER,
      allowNull: false,
    },
    position: {
      type: DataTypes.STRING,
      allowNull: false,
    },
    company: {
      type: DataTypes.STRING,
      allowNull: false,
    },
    location: {
      type: DataTypes.STRING,
      allowNull: false,
    },
    date: {
      type: DataTypes.STRING,
      allowNull: false,
    },
    salary: {
      type: DataTypes.STRING,
      allowNull: false,
    },
    jobUrl: {
      type: DataTypes.STRING,
      allowNull: false,
    },
  },
  {
    sequelize,
    modelName: 'SearchResult',
  }
);

export default SearchResult;

// ./src/models/SearchDefinition.ts
import { Model, DataTypes } from 'sequelize';
import sequelize from '../db'; // Import your Sequelize instance

class SearchDefinition extends Model {
  public id!: number;
  public keyword!: string;
  public location!: string;
  public refreshInterval!: number;
}

SearchDefinition.init(
  {
    id: {
      type: DataTypes.INTEGER,
      primaryKey: true,
      autoIncrement: true,
    },
    keyword: {
      type: DataTypes.STRING,
      allowNull: false,
    },
    location: {
      type: DataTypes.STRING,
      allowNull: false,
    },
    refreshInterval: {
      type: DataTypes.INTEGER,
      allowNull: false,
    },
  },
  {
    sequelize,
    modelName: 'SearchDefinition',
  }
);

export default SearchDefinition;

// ./src/types.ts
export interface JobListing {
  position: string;
  company: string;
  location: string;
  date: string;
  salary: string;
  jobUrl: string;
}

export interface QueryParams {
  keyword?: string;
  location?: string;
}

// ./src/testDatabaseConnections.ts

import sequelize from './db';
import SearchDefinition from './models/SearchDefinition';
import logger from './utils/logger';

(async () => {
  try {
    logger.info('Attempting to authenticate the database connection...');
    await sequelize.authenticate();
    logger.info('Database authentication successful');

    logger.info('Synchronizing models...');
    await sequelize.sync();
    logger.info('Models synchronized successfully.');

    // Test query to check ORM functionality
    logger.info('Testing database query...');
    const searchDefinitions = await SearchDefinition.findAll();
    logger.info('Successfully retrieved search definitions:', {
      count: searchDefinitions.length,
    });
  } catch (error) {
    logger.error('Error during database connection test', {
      error: error instanceof Error ? error.message : String(error),
    });
  } finally {
    await sequelize.close();
    logger.info('Database connection closed.');
  }
})();

// ./src/index.ts

import express from 'express';
import * as dotenv from 'dotenv';
import bodyParser from 'body-parser';
import searchRoutes from './routes/SearchRoutes';
import sequelize from './db';
import SearchDefinition from './models/SearchDefinition';
import { startMonitoringAllSearches } from './services/SearchManager';
import logger from './utils/logger';

// Load environment variables
dotenv.config();

// Handle unhandled promise rejections globally
process.on('unhandledRejection', (reason, promise) => {
  logger.error('Unhandled Rejection at:', { promise, reason: reason instanceof Error ? reason.message : String(reason) });
});

const app = express();
const port = process.env.PORT || 3000;

app.use(bodyParser.json());

app.use((req, res, next) => {
  logger.info(`Request received`, { method: req.method, path: req.path });
  next();
});

// Health check endpoint
app.get('/api/health', (req, res) => {
  res.status(200).send('API is up and running');
});

// Mount API routes
app.use('/api', searchRoutes);

(async () => {
  try {
    // Database checks
    logger.info('Attempting to authenticate the database connection...');
    await sequelize.authenticate();
    logger.info('Database authentication successful');

    logger.info('Synchronizing models...');
    await sequelize.sync();
    logger.info('Models synchronized successfully.');

    // Test query to check ORM functionality
    logger.info('Testing database query...');
    const searchDefinitions = await SearchDefinition.findAll();
    logger.info('Successfully retrieved search definitions:', {
      count: searchDefinitions.length,
    });

    // Start server after successful database checks
    app.listen(port, () => {
      logger.info(`Server running on port ${port}`);
    });

    logger.info('Starting to monitor all searches...');
    await startMonitoringAllSearches();
    logger.info('Started monitoring all searches and synchronization complete');
  } catch (error) {
    logger.error('Error during server startup', {
      error: error instanceof Error ? error.message : String(error),
    });
    process.exit(1); // Exit the process with failure
  }
})();

// ./src/config.ts
import dotenv from 'dotenv';
dotenv.config();

export const dbConfig = {
  username: process.env.DB_USERNAME || 'postgres',
  password: process.env.DB_PASSWORD || '',
  database: process.env.DB_NAME || 'job_service',
  host: process.env.DB_HOST || 'localhost',
  dialect: 'postgres',
};

// ./src/controllers/SearchController.ts

import { Request, Response } from 'express';
import SearchDefinition from '../models/SearchDefinition';
import { scheduleJobForSearch } from '../services/SearchManager'; // Use the correct function name
import logger from '../utils/logger';

export const createSearch = async (req: Request, res: Response) => {
  logger.info('Received request to create search', { body: req.body });

  try {
    const { keyword, location, refreshInterval } = req.body;
    const newSearch = await SearchDefinition.create({ keyword, location, refreshInterval });
    await scheduleJobForSearch(newSearch); // Use the correct function
    res.status(201).json({ message: 'Search created', data: newSearch });
  } catch (error: any) {
    logger.error('Error creating search', { error: error.message });
    res.status(500).json({ error: error.message });
  }
};

export const getAllSearches = async (req: Request, res: Response) => {
  try {
    const searches = await SearchDefinition.findAll();
    res.status(200).json(searches);
  } catch (error: any) {
    logger.error('Error fetching searches', { error: error.message });
    res.status(500).json({ error: error.message });
  }
};

export const updateSearch = async (req: Request, res: Response) => {
  try {
    const { id } = req.params;
    const { keyword, location, refreshInterval } = req.body;
    const search = await SearchDefinition.findByPk(id);

    if (!search) {
      logger.warn('Search not found', { id });
      return res.status(404).json({ error: 'Search not found' });
    }

    search.keyword = keyword || search.keyword;
    search.location = location || search.location;
    search.refreshInterval = refreshInterval || search.refreshInterval;
    await search.save();
    await scheduleJobForSearch(search);
    res.status(200).json(search);
  } catch (error: any) {
    logger.error('Error updating search', { error: error.message });
    res.status(500).json({ error: error.message });
  }
};

export const deleteSearch = async (req: Request, res: Response) => {
  try {
    const { id } = req.params;
    const search = await SearchDefinition.findByPk(id);

    if (!search) {
      logger.warn('Search not found', { id });
      return res.status(404).json({ error: 'Search not found' });
    }

    await search.destroy();
    res.status(200).json({ message: 'Search deleted' });
  } catch (error: any) {
    logger.error('Error deleting search', { error: error.message });
    res.status(500).json({ error: error.message });
  }
};

// ./src/controllers/SearchResultController.ts

import { Request, Response } from 'express';
import SearchResult from '../models/SearchResult';
import logger from '../utils/logger';

// Function to get search results by searchId
export const getSearchResults = async (req: Request, res: Response) => {
  const { id } = req.params;

  try {
    const results = await SearchResult.findAll({
      where: { searchId: id }
    });

    if (results.length === 0) {
      logger.warn('No results found', { searchId: id });
      return res.status(404).json({ message: 'No results found for this search.' });
    }

    logger.info('Results retrieved successfully', { searchId: id });
    res.status(200).json(results);
  } catch (error: any) {
    logger.error('Error fetching search results', { error: error.message });
    res.status(500).json({ error: error.message });
  }
};

// ./src/db.ts

import { Sequelize } from 'sequelize';
import { dbConfig } from './config';
import logger from './utils/logger'; // Import the custom logger

const sequelize = new Sequelize(dbConfig.database, dbConfig.username, dbConfig.password, {
  host: dbConfig.host,
  dialect: 'postgres',
  logging: (msg) => logger.info(`Sequelize: ${msg}`), // Detailed SQL logging
});

export default sequelize;

// ./src/routes/SearchRoutes.ts

import { Router } from 'express';
import { getAllSearches, createSearch, updateSearch, deleteSearch } from '../controllers/SearchController';
import { getSearchResults } from '../controllers/SearchResultController';

const router = Router();

router.get('/searches', getAllSearches);
router.post('/searches', createSearch);
router.put('/searches/:id', updateSearch);
router.delete('/searches/:id', deleteSearch);

// New route to get search results
router.get('/searches/:id/results', getSearchResults);

export default router;

// ./src/services/SearchManager.ts

import nodeSchedule from 'node-schedule';
import SearchDefinition from '../models/SearchDefinition';
import SearchResult from '../models/SearchResult';
import fetchJobListings from './LinkedInScraper';
import logger from '../utils/logger';

const jobs: { [key: number]: nodeSchedule.Job } = {};

export const scheduleJobForSearch = async (search: SearchDefinition) => {
  if (jobs[search.id]) {
    jobs[search.id].cancel();
  }

  logger.info('Scheduling job', { searchId: search.id, refreshInterval: search.refreshInterval });

  const job = nodeSchedule.scheduleJob(`*/${search.refreshInterval} * * * *`, async () => {
    try {
      const jobListings = await fetchJobListings({
        keyword: search.keyword,
        location: search.location,
      });

      logger.info('Fetched job listings', { count: jobListings.length });

      for (const listing of jobListings) {
        try {
          await SearchResult.create({
            searchId: search.id,
            position: listing.position,
            company: listing.company,
            location: listing.location,
            date: listing.date,
            salary: listing.salary,
            jobUrl: listing.jobUrl,
          });
          logger.info('Job listing saved', { listing });
        } catch (error) {
          logger.error('Error saving job listing', {
            error: error instanceof Error ? error.message : String(error),
            listing,
          });
        }
      }

      logger.info('Job listings processed', { searchId: search.id, count: jobListings.length });
    } catch (error) {
      logger.error('Error during job execution', {
        error: error instanceof Error ? error.message : String(error),
      });
    }
  });

  jobs[search.id] = job;
};

export const startMonitoringAllSearches = async () => {
  try {
    const searches = await SearchDefinition.findAll();
    searches.forEach(scheduleJobForSearch);
    logger.info('Started monitoring all searches');
  } catch (error) {
    logger.error('Error starting monitoring of searches', {
      error: error instanceof Error ? error.message : String(error),
    });
  }
};

export const stopJob = (searchId: number) => {
  if (jobs[searchId]) {
    jobs[searchId].cancel();
    delete jobs[searchId];
    logger.info('Stopped job', { searchId });
  }
};

// ./src/services/LinkedInService.ts

import { RestliClient } from 'linkedin-api-client';
import dotenv from 'dotenv';

dotenv.config();

const accessToken = process.env.ACCESS_TOKEN || process.env.LINKEDIN_ACCESS_TOKEN;

if (!accessToken) {
  throw new Error('Access token is not defined. Please check your environment variables.');
}

const restliClient = new RestliClient();

const fetchJobListings = async (queryObject: { keyword: string; location: string }) => {
  try {
    const response = await restliClient.get({
      resourcePath: `jobSearch?q=jobs&keywords=${encodeURIComponent(queryObject.keyword)}&location=${encodeURIComponent(queryObject.location)}`,
      accessToken: accessToken as string,
    });
    return response.data.elements;
  } catch (error) {
    console.error('Error fetching job listings:', error);
    return [];
  }
};

export default fetchJobListings;

// ./src/services/LinkedInScraper.ts

import puppeteer from 'puppeteer';
import { JobListing } from '../types';
import logger from '../utils/logger';
import fs from 'fs';

const fetchJobListings = async (queryObject: { keyword: string; location: string }): Promise<JobListing[]> => {
  const { keyword, location } = queryObject;
  const url = `https://www.linkedin.com/jobs/search/?keywords=${encodeURIComponent(keyword)}&location=${encodeURIComponent(location)}`;

  logger.info('Starting job listings scraping', { keyword, location });

  let browser;
  try {
    browser = await puppeteer.launch({ headless: false }); // Set headless: false to see the browser
    const page = await browser.newPage();
    await page.goto(url, { waitUntil: 'networkidle2' });

    // Log the current URL and page content length
    logger.info('Page loaded', { url: page.url() });
    const pageContent = await page.content();
    logger.info('Page content length', { length: pageContent.length });

    // Save the HTML content to a file for inspection
    fs.writeFileSync('scrapedPage.html', pageContent);

    // Wait for a specific selector to ensure the page content is fully loaded
    await page.waitForSelector('.result-card__contents');

    // Scrape the job listings
    const jobListings: JobListing[] = await page.evaluate(() => {
      const jobs: JobListing[] = [];
      const jobElements = document.querySelectorAll('.result-card__contents');

      jobElements.forEach(jobElement => {
        const position = (jobElement.querySelector('.result-card__title') as HTMLElement)?.innerText || '';
        const company = (jobElement.querySelector('.result-card__subtitle') as HTMLElement)?.innerText || '';
        const location = (jobElement.querySelector('.job-result-card__location') as HTMLElement)?.innerText || '';
        const date = (jobElement.querySelector('time') as HTMLTimeElement)?.getAttribute('datetime') || '';
        const jobUrl = (jobElement.querySelector('a') as HTMLAnchorElement)?.href || '';

        if (position && company && location && date && jobUrl) {
          jobs.push({ position, company, location, date, salary: '', jobUrl });
        }
      });

      return jobs;
    });

    logger.info('Job listings scraped successfully', { count: jobListings.length });
    logger.info('Extracted job listings', { jobListings });
    return jobListings;

  } catch (error: any) {
    logger.error('Error occurred during scraping', { error: error.message });
    return [];
  } finally {
    if (browser) {
      await browser.close();
      logger.info('Browser closed');
    }
  }
};

export default fetchJobListings;

